{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d470079",
   "metadata": {},
   "source": [
    "# <ins> Milestone 1 </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997cda7",
   "metadata": {},
   "source": [
    "The following presents the code for converting the file \"ir-anthology-07-11-2021-ss23\" into a new file with the name \"ir-anthology-final\" in the correct format into the directory \"Created Data\". In addition, this newly created file is registered together with the requested XML file called \"topics\" in \"Tira\". <br/><br/>Afterwards, a reflection will be presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c9955",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2b548",
   "metadata": {},
   "source": [
    "### Formatting \"ir-anthology-07-11-2021-ss23\" with the fields \"doc_id\" and \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfcbfac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:21.381943Z",
     "start_time": "2023-04-28T17:05:21.375467Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json #Module to work on JSON data\n",
    "import os #Module for interacting with the operating system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161d78f",
   "metadata": {},
   "source": [
    "Importing necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff1288a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:21.395638Z",
     "start_time": "2023-04-28T17:05:21.380942Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDirectory():\n",
    "    return os.path.join(os.getcwd(), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f1b88",
   "metadata": {},
   "source": [
    "Function to get the current directory in the right format.<br/><br/>Return: <br/> &emsp; Current directory as String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3aba6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:21.395638Z",
     "start_time": "2023-04-28T17:05:21.394638Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xmlFileName = \"dnc-limited-topics.xml\"\n",
    "inputFileName = \"ir-anthology-07-11-2021-ss23.jsonl\"\n",
    "outputFileName = \"dnc-limited--documents.jsonl\"\n",
    "inputFilePath = getDirectory() + \"data/\" + inputFileName\n",
    "outputFilePath = getDirectory() + \"data/\" + outputFileName\n",
    "xmlFilePath = getDirectory() + \"data/\" + xmlFileName\n",
    "irdatasetName = \"dnc-limited-dataset-tira/\"\n",
    "irdatasetPath = getDirectory() + irdatasetName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9535a3",
   "metadata": {},
   "source": [
    "File names and thier paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc372c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:21.430882Z",
     "start_time": "2023-04-28T17:05:21.395638Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkForFile(file_path, file_name):\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f\"The File {file_name} already exists.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"The File {file_name} doesn´t exist.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205acd02",
   "metadata": {},
   "source": [
    "Function to check if file already exists at the given path. <br/><br/>Return: <br/> &emsp; True: If file exists <br/> &emsp; False: If file doesn´t exist <br/><br/>Output: <br/> &emsp; Small information text, whether the file exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980d4ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:21.430882Z",
     "start_time": "2023-04-28T17:05:21.406769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getEntriesToJSONL(inputFilePath, outputFilePath, outputFileName):\n",
    "    ##If the File doesn´t exist\n",
    "    if checkForFile(outputFilePath,outputFileName) == False:\n",
    "        with open(outputFilePath, 'w') as f:\n",
    "            #Try to create the \"outputFile\" as an empty file and give the following output\n",
    "            try:\n",
    "                f.write(json.dumps(\"\"))\n",
    "                print(f\"The File {outputFileName} was created in the following path: {outputFilePath}\")\n",
    "            #If the try failed, return the following output\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred creating the File {outputFileName}: {e}\")\n",
    "\n",
    "    # Open the input-JSONL-file and the output-JSONL-file\n",
    "    with open(inputFilePath, \"r\") as input_file, open(outputFilePath, \"w\") as output_file:\n",
    "        # Iterate over each line (object) of the input-JSONL-file\n",
    "        for line in input_file:\n",
    "            lineJSON = json.loads(line) # Load the current line as JSON\n",
    "            array = [] #Array for the values of the current line\n",
    "            for key in lineJSON:\n",
    "                array.append(lineJSON[key]) #Append the value for each key to the array\n",
    "            stringJSON = \" \".join(str(item) for item in array) #Create a string with the values of the object for the \"text\" field\n",
    "\n",
    "            # Create an object with the \"doc_id\" (id of the object) and \"text\" fields \n",
    "            finalObject = {\"doc_id\": lineJSON[\"id\"], \"text\": stringJSON}\n",
    "\n",
    "            # Write the finalObject as JSON to the output JSONL file\n",
    "            output_file.write(json.dumps(finalObject) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf1c73",
   "metadata": {},
   "source": [
    "Function to convert the \"inputFile\" to an \"outputFile\" as JSONL-File by the following steps: <br/> &emsp; 1. First check if \"outputFile\" already exists and if necessary create it. <br/> &emsp; 2. Convert the \"inputFile\" with the \"doc_id\" and \"text\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44131eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:05:22.868137Z",
     "start_time": "2023-04-28T17:05:21.410884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The File ir-anthology-final.jsonl already exists.\n"
     ]
    }
   ],
   "source": [
    "getEntriesToJSONL(inputFilePath, outputFilePath, outputFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456578a",
   "metadata": {},
   "source": [
    "Execute the function to convert the \"inputFile\" <br/><br/> Output: <br/> &emsp; If file exists or has been created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d944e",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9269bbc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T15:22:20.172500Z",
     "start_time": "2023-04-29T15:22:17.950686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context:\n",
      "#1 transferring context: 2B 0.0s done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile.iranthology\n",
      "#2 transferring dockerfile: 228B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/webis/tira-ir-datasets-starter:0.0.47\n",
      "#3 DONE 0.6s\n",
      "\n",
      "#4 [1/2] FROM docker.io/webis/tira-ir-datasets-starter:0.0.47@sha256:fc8682857aa816f4b8311f0a60e7a677978707ab101f5732b87f3da004b424b8\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 48B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [2/2] COPY iranthology-dnc-limited.py /usr/lib/python3.8/site-packages/ir_datasets/datasets_in_progress/\n",
      "#6 CACHED\n",
      "\n",
      "#7 exporting to image\n",
      "#7 exporting layers done\n",
      "#7 writing image sha256:0b4b363cb17091a7a4d5f40c4f8bef8c9a7e59d7781c58ad4be685e58d6debfc done\n",
      "#7 naming to docker.io/library/dnc-limited-ir-dataset done\n",
      "#7 DONE 0.0s\n"
     ]
    }
   ],
   "source": [
    "!docker build -t dnc-limited-ir-dataset -f Dockerfile.iranthology ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b1123",
   "metadata": {},
   "source": [
    "Building a docker image for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5efcbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T15:25:33.187606Z",
     "start_time": "2023-04-29T15:25:32.446265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: tira-run [-h] [--input-directory INPUT_DIRECTORY]\n",
      "                [--input-run INPUT_RUN] (--image IMAGE | --approach APPROACH)\n",
      "                [--command COMMAND] [--verbose VERBOSE] [--dry-run DRY_RUN]\n",
      "                [--allow-network ALLOW_NETWORK]\n",
      "                [--output-directory OUTPUT_DIRECTORY]\n",
      "tira-run: error: unrecognized arguments: --ir_datasets_id iranthology-dnc-limited --output_dataset_path $outputDir'\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(irdatasetPath):\n",
    "    print('The folder already exists! Please delete the folder to recreate the data.')\n",
    "else:\n",
    "    !tira-run --output-directory ${PWD}/dnc-limited-dataset-tira --image dnc-limited-ir-dataset --allow-network true --command '/irds_cli.sh --ir_datasets_id iranthology-dnc-limited --output_dataset_path $outputDir'\n",
    "    print('The folder has been created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check, if the tira data already have been created and if needs, create them!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "7ccef287",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd58736",
   "metadata": {},
   "source": [
    "The file \"topics.xml\", which contains the topics, can be found in the \"CreatedData\" directory. <br/>Below you will find the section of the topic with the person who created it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e064ce6",
   "metadata": {},
   "source": [
    "Topic 1 by Constantin Urbainsky:\n",
    "```xml\n",
    "<topic number=\"1\">\n",
    "  <title>machine learnign for more relevant results</title>\n",
    "  <description>Which papers describe methods to find more relevant results using machine learning?</description>\n",
    "  <narrative>\n",
    "      Relevant papers describe one or more methods to find more relevant results using machine learning. \n",
    "      Papers about just machine learning in IR in general or papers just about finding more relevant results are not \n",
    "      relevant. \n",
    "  </narrative>\n",
    "</topic>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27547c6",
   "metadata": {},
   "source": [
    "Topic 2 by Nils Harbach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e9086",
   "metadata": {},
   "source": [
    "<topic number=\"2\">\n",
    "  <title>Crawling websites using machine learning</title>\n",
    "  <description>Papers that describe how to use AI to crawl the context of websites more efficient.</description>\n",
    "  <narrative>Papers in this topic describe methods and algorithms to use machine learning for crawling. They also contain information on the latest research findings on the topic. Papers about crawling methods without AI are not relevant for this topic.</narrative>\n",
    "</topic>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2b5a8",
   "metadata": {},
   "source": [
    "Topic 3 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8234aac",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348114b",
   "metadata": {},
   "source": [
    "Topic 4 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83e3c4",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841ead0",
   "metadata": {},
   "source": [
    "Topic 5 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f8d2c",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bf3c1",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999e24a",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
