{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d470079",
   "metadata": {},
   "source": [
    "# <ins> Milestone 1 </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997cda7",
   "metadata": {},
   "source": [
    "The following presents the code for converting the file \"ir-anthology-07-11-2021-ss23\" into a new file with the name \"ir-anthology-final\" in the correct format into the directory \"Created Data\". In addition, this newly created file is registered together with the requested XML file called \"topics\" in \"Tira\". <br/><br/>Afterwards, a reflection will be presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c9955",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2b548",
   "metadata": {},
   "source": [
    "### Formatting \"ir-anthology-07-11-2021-ss23\" with the fields \"doc_id\" and \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cfcbfac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:44.886177Z",
     "end_time": "2023-04-30T23:41:44.888702Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json #Module to work on JSON data\n",
    "import os #Module for interacting with the operating system\n",
    "import platform #Module to check the current platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161d78f",
   "metadata": {},
   "source": [
    "Importing necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ff1288a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:44.886685Z",
     "end_time": "2023-04-30T23:41:45.758184Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDirectory():\n",
    "    return os.path.join(os.getcwd(), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f1b88",
   "metadata": {},
   "source": [
    "Function to get the current directory in the right format.<br/><br/>Return: <br/> &emsp; Current directory as String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f3aba6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:45.758184Z",
     "end_time": "2023-04-30T23:41:45.958472Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xmlFileName = \"dnc-limited-topics.xml\"\n",
    "inputFileName = \"ir-anthology-07-11-2021-ss23.jsonl\"\n",
    "outputFileName = \"dnc-limited-documents.jsonl\"\n",
    "\n",
    "\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    irdatasetName = \"dnc-limited-dataset-tira/\"\n",
    "    directoryData = \"data/\"\n",
    "else:\n",
    "    irdatasetName = \"dnc-limited-dataset-tira\\\\\"\n",
    "    directoryData = \"data\\\\\"\n",
    "\n",
    "inputFilePath = getDirectory() + directoryData + inputFileName\n",
    "outputFilePath = getDirectory() + directoryData + outputFileName\n",
    "xmlFilePath = getDirectory() + directoryData + xmlFileName\n",
    "irdatasetPath = getDirectory() + irdatasetName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9535a3",
   "metadata": {},
   "source": [
    "File names and thier paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc372c51",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:46.004155Z",
     "end_time": "2023-04-30T23:41:46.468628Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkForFile(file_path, file_name):\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f\"The File {file_name} already exists.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"The File {file_name} doesn´t exist.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205acd02",
   "metadata": {},
   "source": [
    "Function to check if file already exists at the given path. <br/><br/>Return: <br/> &emsp; True: If file exists <br/> &emsp; False: If file doesn´t exist <br/><br/>Output: <br/> &emsp; Small information text, whether the file exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "980d4ecf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:46.470630Z",
     "end_time": "2023-04-30T23:41:46.763532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getEntriesToJSONL(inputFilePath, outputFilePath, outputFileName):\n",
    "    ##If the File doesn´t exist\n",
    "    if checkForFile(outputFilePath,outputFileName) == False:\n",
    "        with open(outputFilePath, 'w') as f:\n",
    "            #Try to create the \"outputFile\" as an empty file and give the following output\n",
    "            try:\n",
    "                f.write(json.dumps(\"\"))\n",
    "                print(f\"The File {outputFileName} was created in the following path: {outputFilePath}\")\n",
    "            #If the try failed, return the following output\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred creating the File {outputFileName}: {e}\")\n",
    "\n",
    "    # Open the input-JSONL-file and the output-JSONL-file\n",
    "    with open(inputFilePath, \"r\") as input_file, open(outputFilePath, \"w\") as output_file:\n",
    "        # Iterate over each line (object) of the input-JSONL-file\n",
    "        for line in input_file:\n",
    "            lineJSON = json.loads(line) # Load the current line as JSON\n",
    "            array = [] #Array for the values of the current line\n",
    "            for key in lineJSON:\n",
    "                array.append(lineJSON[key]) #Append the value for each key to the array\n",
    "            stringJSON = \" \".join(str(item) for item in array) #Create a string with the values of the object for the \"text\" field\n",
    "\n",
    "            # Create an object with the \"doc_id\" (id of the object) and \"text\" fields \n",
    "            finalObject = {\"doc_id\": lineJSON[\"id\"], \"text\": stringJSON}\n",
    "\n",
    "            # Write the finalObject as JSON to the output JSONL file\n",
    "            output_file.write(json.dumps(finalObject) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf1c73",
   "metadata": {},
   "source": [
    "Function to convert the \"inputFile\" to an \"outputFile\" as JSONL-File by the following steps: <br/> &emsp; 1. First check if \"outputFile\" already exists and if necessary create it. <br/> &emsp; 2. Convert the \"inputFile\" with the \"doc_id\" and \"text\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44131eb1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:46.766037Z",
     "end_time": "2023-04-30T23:41:48.641274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The File dnc-limited-documents.jsonl already exists.\n"
     ]
    }
   ],
   "source": [
    "getEntriesToJSONL(inputFilePath, outputFilePath, outputFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456578a",
   "metadata": {},
   "source": [
    "Execute the function to convert the \"inputFile\" <br/><br/> Output: <br/> &emsp; If file exists or has been created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d944e",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9269bbc2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:48.643276Z",
     "end_time": "2023-04-30T23:41:51.367535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context: 2B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile.iranthology\n",
      "#2 transferring dockerfile: 290B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/webis/tira-ir-datasets-starter:0.0.54\n",
      "#3 DONE 0.5s\n",
      "\n",
      "#4 [1/2] FROM docker.io/webis/tira-ir-datasets-starter:0.0.54@sha256:2d59e9cd38cfdde34662f8fba5b426dd1f2a7b29e54e50ce8be676d0ad3af2ad\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 59.78MB 0.5s done\n",
      "#5 DONE 0.5s\n",
      "\n",
      "#6 [2/2] COPY iranthology-dnc-limited.py data/dnc-limited-topics.xml  data/dnc-limited-documents.jsonl /usr/lib/python3.8/site-packages/ir_datasets/datasets_in_progress/\n",
      "#6 CACHED\n",
      "\n",
      "#7 exporting to image\n",
      "#7 exporting layers done\n",
      "#7 writing image sha256:4029bbb09bfc46cedcb917c3dfd154b2e8db815dbfc5a6efc568b1fd14e4bc39 done\n",
      "#7 naming to docker.io/library/dnc-limited-ir-dataset done\n",
      "#7 DONE 0.0s\n"
     ]
    }
   ],
   "source": [
    "!docker build -t dnc-limited-ir-dataset -f Dockerfile.iranthology ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b1123",
   "metadata": {},
   "source": [
    "Building a docker image for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c5efcbb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-30T23:41:51.370760Z",
     "end_time": "2023-04-30T23:42:09.998249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running Python on Windows.\n",
      "Task: Full-Rank -> create files: \n",
      " documents.jsonl \n",
      " queries.jsonl \n",
      " qrels.txt \n",
      " at /tira-data/output/\n",
      "\n",
      "\n",
      "Load Documents: 0it [00:00, ?it/s]\n",
      "\n",
      "Load Documents: 375it [00:00, 3749.60it/s]\n",
      "\n",
      "Load Documents: 1380it [00:00, 7449.92it/s]\n",
      "\n",
      "Load Documents: 2488it [00:00, 9103.99it/s]\n",
      "\n",
      "Load Documents: 3827it [00:00, 10793.41it/s]\n",
      "\n",
      "Load Documents: 4984it [00:00, 11072.83it/s]\n",
      "\n",
      "Load Documents: 6324it [00:00, 11861.22it/s]\n",
      "\n",
      "Load Documents: 7530it [00:00, 11922.73it/s]\n",
      "\n",
      "Load Documents: 8723it [00:00, 11912.13it/s]\n",
      "\n",
      "Load Documents: 9915it [00:00, 11459.88it/s]\n",
      "\n",
      "Load Documents: 11065it [00:01, 10811.27it/s]\n",
      "\n",
      "Load Documents: 12452it [00:01, 11689.53it/s]\n",
      "\n",
      "Load Documents: 13633it [00:01, 11713.95it/s]\n",
      "\n",
      "Load Documents: 14813it [00:01, 11464.18it/s]\n",
      "\n",
      "Load Documents: 15966it [00:01, 9644.05it/s] \n",
      "\n",
      "Load Documents: 17705it [00:01, 11646.33it/s]\n",
      "\n",
      "Load Documents: 19165it [00:01, 12438.02it/s]\n",
      "\n",
      "Load Documents: 20466it [00:01, 12594.55it/s]\n",
      "\n",
      "Load Documents: 21767it [00:01, 11987.70it/s]\n",
      "\n",
      "Load Documents: 23000it [00:02, 11816.54it/s]\n",
      "\n",
      "Load Documents: 24205it [00:02, 11615.69it/s]\n",
      "\n",
      "Load Documents: 25582it [00:02, 12218.44it/s]\n",
      "\n",
      "Load Documents: 27367it [00:02, 13819.98it/s]\n",
      "\n",
      "Load Documents: 28795it [00:02, 13946.31it/s]\n",
      "\n",
      "Load Documents: 30203it [00:02, 13967.96it/s]\n",
      "\n",
      "Load Documents: 31610it [00:02, 13643.78it/s]\n",
      "\n",
      "Load Documents: 32983it [00:02, 13028.94it/s]\n",
      "\n",
      "Load Documents: 34296it [00:02, 12124.11it/s]\n",
      "\n",
      "Load Documents: 35525it [00:02, 12162.13it/s]\n",
      "\n",
      "Load Documents: 36930it [00:03, 12690.05it/s]\n",
      "\n",
      "Load Documents: 38366it [00:03, 13166.68it/s]\n",
      "\n",
      "Load Documents: 39694it [00:03, 12946.97it/s]\n",
      "\n",
      "Load Documents: 41018it [00:03, 13028.10it/s]\n",
      "\n",
      "Load Documents: 42395it [00:03, 13244.12it/s]\n",
      "\n",
      "Load Documents: 44420it [00:03, 15304.15it/s]\n",
      "\n",
      "Load Documents: 46438it [00:03, 16745.28it/s]\n",
      "\n",
      "Load Documents: 48631it [00:03, 18285.88it/s]\n",
      "\n",
      "Load Documents: 50498it [00:03, 18397.13it/s]\n",
      "\n",
      "Load Documents: 52343it [00:04, 16171.36it/s]\n",
      "\n",
      "Load Documents: 53673it [00:04, 12825.35it/s]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(irdatasetPath):\n",
    "    print(irdatasetPath)\n",
    "    print('The folder already exists! Please delete the folder to recreate the data.')\n",
    "else:\n",
    "    if platform.system() == 'Windows':\n",
    "        print(\"You are running Python on Windows.\")\n",
    "        !tira-run --output-directory %cd%\\dnc-limited-dataset-tira --image dnc-limited-ir-dataset --allow-network true --command \"/irds_cli.sh --ir_datasets_id iranthology-dnc-limited --output_dataset_path $outputDir\"\n",
    "    else:\n",
    "        print(\"You are not running Python on Windows.\")\n",
    "        !tira-run --output-directory ${PWD}/dnc-limited-dataset-tira --image dnc-limited-ir-dataset --allow-network true --command '/irds_cli.sh --ir_datasets_id iranthology-dnc-limited --output_dataset_path $outputDir'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check, if the tira data already have been created and if needs, create them!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "7ccef287",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd58736",
   "metadata": {},
   "source": [
    "The file \"topics.xml\", which contains the topics, can be found in the \"CreatedData\" directory. <br/>Below you will find the section of the topic with the person who created it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e064ce6",
   "metadata": {},
   "source": [
    "Topic 1 by Constantin Urbainsky:\n",
    "```xml\n",
    "<topic number=\"1\">\n",
    "  <title>machine learnign for more relevant results</title>\n",
    "  <description>Which papers describe methods to find more relevant results using machine learning?</description>\n",
    "  <narrative>\n",
    "      Relevant papers describe one or more methods to find more relevant results using machine learning. \n",
    "      Papers about just machine learning in IR in general or papers just about finding more relevant results are not \n",
    "      relevant. \n",
    "  </narrative>\n",
    "</topic>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27547c6",
   "metadata": {},
   "source": [
    "Topic 2 by Nils Harbach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e9086",
   "metadata": {},
   "source": [
    "<topic number=\"2\">\n",
    "  <title>Crawling websites using machine learning</title>\n",
    "  <description>Papers that describe how to use AI to crawl the context of websites more efficient.</description>\n",
    "  <narrative>Papers in this topic describe methods and algorithms to use machine learning for crawling. They also contain information on the latest research findings on the topic. Papers about crawling methods without AI are not relevant for this topic.</narrative>\n",
    "</topic>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2b5a8",
   "metadata": {},
   "source": [
    "Topic 3 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8234aac",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348114b",
   "metadata": {},
   "source": [
    "Topic 4 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83e3c4",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841ead0",
   "metadata": {},
   "source": [
    "Topic 5 by _______:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f8d2c",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bf3c1",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999e24a",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
