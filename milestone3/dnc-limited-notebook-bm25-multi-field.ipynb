{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb68a97a",
   "metadata": {},
   "source": [
    "# <ins> Milestone 3 </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b479a05",
   "metadata": {},
   "source": [
    "## Information for BM25\n",
    "\n",
    "The following Code is for the use inside the \"pyterrier\" Docker image and couldnÂ´t function, if you want to execute it in your notebook!\n",
    "\n",
    "Please follow these steps to create the needed output:\n",
    "\n",
    "### Pre-condition\n",
    "\n",
    "1. Navigate in your terminal to the \"milestone3\" folder and open \"Docker Desktop\"\n",
    "\n",
    "2. Pull the image of the \"milestone1\" with the qrels command\n",
    "    ```\n",
    "    docker pull registry.webis.de/code-research/tira/tira-user-ir-lab-sose-2023-dnc-limited/ir-datasets:0.0.1\n",
    "    ```\n",
    "3. Execute the tira-run command for the \"milestone1\" to get the needed output:\n",
    "    ```\n",
    "    tira-run --output-directory ${PWD}/iranthology-dataset-tira --image registry.webis.de/code-research/tira/tira-user-ir-lab-sose-2023-dnc-limited/ir-datasets:0.0.1 --allow-network true --command '/irds_cli.sh --ir_datasets_id iranthology-dnc-limited --output_dataset_path $outputDir'\n",
    "    ```\n",
    "   \n",
    "### Milestone 3\n",
    "\n",
    "4. Build an image for the current milestone:\n",
    "    ```\n",
    "    docker build -t milestone3 .\n",
    "    ```\n",
    "5. Run this image:\n",
    "    ```\n",
    "    docker run -p 8888:8888 --rm -ti -v ${PWD}:/workspace --entrypoint jupyter milestone3  notebook --allow-root --ip 0.0.0.0\n",
    "    ```\n",
    "6. Execute this notebook as tira would do:\n",
    "    ```\n",
    "    tira-run --input-directory ${PWD}/iranthology-dataset-tira --output-directory ${PWD}/bm25-multi-field-output --image milestone3 --command '/workspace/run-pyterrier-notebook.py --input $inputDataset --output $outputDir --notebook /workspace/dnc-limited-notebook-bm25-multi-field.ipynb'\n",
    "    ```\n",
    "7. Render results:\n",
    "    ```\n",
    "    tira-run --output-directory ${PWD}/bm25-multi-field-output --image registry.webis.de/code-research/tira/tira-user-ir-lab-sose-2023-dnc-limited/ir-datasets:0.0.1 --allow-network true --command 'diffir --dataset iranthology-dnc-limited --web $outputDir/run.txt > $outputDir/run.html'\n",
    "    ```\n",
    "8. Evaluate the effectiveness of the baseline on your relevance judgments:\n",
    "    ```\n",
    "    tira-run --input-directory ${PWD}/bm25-multi-field-output --image registry.webis.de/code-research/tira/tira-user-ir-lab-sose-2023-dnc-limited/ir-datasets:0.0.1 --allow-network true --command 'ir_measures iranthology-dnc-limited $inputDataset/run.txt nDCG@10 MRR P@10 Recall@100'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a05dba",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8aed7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T17:11:08.507640300Z",
     "start_time": "2023-06-24T17:11:08.116402700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0be858",
   "metadata": {},
   "source": [
    "Importing all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddbf7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T17:11:08.782155100Z",
     "start_time": "2023-06-24T17:11:08.509643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start PyTerrier with version=5.7, helper_version=0.0.7, no_download=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will read the input data from ./iranthology-dataset-tira.\n",
      "The output directory is /tmp/\n"
     ]
    }
   ],
   "source": [
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "#Using the \"get_input_directory_andoutputdirectory\" function code from \"tira.third_party_integrations\" to set the input andoutout directory\n",
    "default_input = './iranthology-dataset-tira'\n",
    "default_output = '/tmp/'\n",
    "\n",
    "input_directory = os.environ.get('TIRA_INPUT_DIRECTORY', None)\n",
    "if not input_directory:\n",
    "    input_directory = default_input\n",
    "\n",
    "output_directory = os.environ.get('TIRA_OUTPUT_DIRECTORY', default_output)\n",
    "\n",
    "print(f'I will read the input data from {input_directory}.')\n",
    "print(f'The output directory is {output_directory}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b1e3d",
   "metadata": {},
   "source": [
    "Ensure that PyTerrier is loaded and setting the input and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06dce6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input directory contains following files:\n",
      "total 146M\r\n",
      "drwxrwxrwx 1 root root 4.0K Jun 24 17:11 .\r\n",
      "drwxrwxrwx 1 root root 4.0K Jun 24 17:11 ..\r\n",
      "-rw-r--r-- 1 root root 146M Jun 24 17:11 documents.jsonl\r\n",
      "-rw-r--r-- 1 root root   46 Jun 24 17:11 metadata.json\r\n",
      "-rw-r--r-- 1 root root 3.0K Jun 24 17:11 queries.jsonl\r\n",
      "-rw-r--r-- 1 root root 3.8K Jun 24 17:11 queries.xml\r\n"
     ]
    }
   ],
   "source": [
    "print(\"The input directory contains following files:\")\n",
    "!ls -lha {input_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9536b",
   "metadata": {},
   "source": [
    "Checking the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3ea283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing the first 5 documents from the imported documents.jsonl:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>original_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.sigirconf_workshop-2019birndl.0</td>\n",
       "      <td>CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de:0074-2414-3 https://dblp.org/rec/conf/sigir/2019birndl.bib ...</td>\n",
       "      <td>{'doc_id': '2019.sigirconf_workshop-2019birndl.0', 'text': 'CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.sigirconf_workshop-2019birndl.1</td>\n",
       "      <td>DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...</td>\n",
       "      <td>{'doc_id': '2019.sigirconf_workshop-2019birndl.1', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.sigirconf_workshop-2019birndl.2</td>\n",
       "      <td>DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...</td>\n",
       "      <td>{'doc_id': '2019.sigirconf_workshop-2019birndl.2', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.sigirconf_workshop-2019birndl.3</td>\n",
       "      <td>DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...</td>\n",
       "      <td>{'doc_id': '2019.sigirconf_workshop-2019birndl.3', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.sigirconf_workshop-2019birndl.4</td>\n",
       "      <td>DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...</td>\n",
       "      <td>{'doc_id': '2019.sigirconf_workshop-2019birndl.4', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  docno  \\\n",
       "0  2019.sigirconf_workshop-2019birndl.0   \n",
       "1  2019.sigirconf_workshop-2019birndl.1   \n",
       "2  2019.sigirconf_workshop-2019birndl.2   \n",
       "3  2019.sigirconf_workshop-2019birndl.3   \n",
       "4  2019.sigirconf_workshop-2019birndl.4   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "0  CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de:0074-2414-3 https://dblp.org/rec/conf/sigir/2019birndl.bib ...   \n",
       "1  DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...   \n",
       "2  DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...   \n",
       "3  DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...   \n",
       "4  DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing fo...   \n",
       "\n",
       "                                                                                                                                       original_document  \n",
       "0  {'doc_id': '2019.sigirconf_workshop-2019birndl.0', 'text': 'CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de...  \n",
       "1  {'doc_id': '2019.sigirconf_workshop-2019birndl.1', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...  \n",
       "2  {'doc_id': '2019.sigirconf_workshop-2019birndl.2', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...  \n",
       "3  {'doc_id': '2019.sigirconf_workshop-2019birndl.3', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...  \n",
       "4  {'doc_id': '2019.sigirconf_workshop-2019birndl.4', 'text': 'DBLP:conf/sigir/2019birndl Proceedings of the 4th Joint Workshop on Bibliometric-enhan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150) #Setting the maximum width for better visibility\n",
    "\n",
    "docs_df = pd.read_json(f'{input_directory}/documents.jsonl', lines=True) #Consider the textural documents in a dataframe\n",
    "\n",
    "print(\"Viewing the first 5 documents from the imported documents.jsonl:\")\n",
    "docs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f2b46",
   "metadata": {},
   "source": [
    "Function to get Values of a String in Json format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab8c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded queries are:\n",
      "  qid                                        query\n",
      "0   1   machine learning for more relevant results\n",
      "1   2     crawling websites using machine learning\n",
      "2   3              recommenders influence on users\n",
      "3   4                search engine caching effects\n",
      "4   5                     consumer product reviews\n",
      "5   6                 limitations machine learning\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_12/304837734.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mdocuments\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_directory\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/documents.jsonl'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mdocuments\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'docno'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'docno'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'text'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'title'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'title'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'abstract'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'abstract'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_12/304837734.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mdocuments\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_directory\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'/documents.jsonl'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mdocuments\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'docno'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'docno'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'text'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'title'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'title'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'abstract'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'abstract'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "queries = pt.io.read_topics(input_directory + '/queries.xml', format='trecxml') #Excracting the queries as trecxml format\n",
    "\n",
    "#Viewing the queries\n",
    "print(\"The loaded queries are:\")\n",
    "print(queries)\n",
    "\n",
    "documents = [json.loads(i) for i in open(input_directory + '/documents.jsonl', 'r')]\n",
    "documents = [{'docno': i['docno'], 'text': i['text'], 'title': i['original_document']['title'], 'abstract': i['original_document']['abstract']} for i in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26664e2a",
   "metadata": {},
   "source": [
    "Loading all needed data (queries and documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -Rf ./index #If the index folder exists, ten delete it and its content\n",
    "\n",
    "iter_indexer = pt.IterDictIndexer(\"./index\", meta={'docno' : 100, 'title': 10240, 'abstract': 10240, 'text': 10240}, blocks=True)\n",
    "index_ref = iter_indexer.index(tqdm(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5cd21f",
   "metadata": {},
   "source": [
    "Create the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fa1f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\", verbose=True, metadata=['docno', 'text', 'title', 'abstract'])\n",
    "\n",
    "bm25_title = pt.text.scorer(body_attr=\"title\", wmodel=\"BM25\")\n",
    "bm25_abstract = pt.text.scorer(body_attr=\"abstract\", wmodel=\"BM25\")\n",
    "bm25_text = pt.text.scorer(body_attr=\"text\", wmodel=\"BM25\")\n",
    "\n",
    "\n",
    "# Here some \"random\" ranking formula that puts the highest weight on the title and\n",
    "# reduces the weight of matches on the text field\n",
    "# Here is big potential for improvements :)\n",
    "combined_bm25_score = ((2*bm25_title) + (1*bm25_abstract) + (0.5*bm25_text))\n",
    "\n",
    "\n",
    "dph_title = pt.text.scorer(body_attr=\"title\", wmodel=\"DPH\")\n",
    "dph_abstract = pt.text.scorer(body_attr=\"abstract\", wmodel=\"DPH\")\n",
    "dph_text = pt.text.scorer(body_attr=\"text\", wmodel=\"DPH\")\n",
    "\n",
    "# Here some \"random\" ranking formula that puts the highest weight on the title and\n",
    "# reduces the weight of matches on the text field\n",
    "# Here is big potential for improvements :)\n",
    "combined_dph_score = ((2*dph_title) + (1*dph_abstract) + (0.5*dph_text))\n",
    "\n",
    "# The overall Pipeline: We retrieve the top-1000 results from BM25 that we re-rank using the combined BM25 and DPH scores.\n",
    "# We just add the scores of BM25 and DPH\n",
    "# Here is big potential for improvements :)\n",
    "retrieval_pipeline = bm25 %1000 >> combined_bm25_score + combined_dph_score\n",
    "bm25.search(\"Limitations machine learning\") #viewing the docid and score of the query \"Limitations machine learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9622d",
   "metadata": {},
   "source": [
    "Create Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d118af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(\"Index informations:\")\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db1200",
   "metadata": {},
   "source": [
    "Getting information about your created index directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a8a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run = bm25(queries[:1])\n",
    "run.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f656a8b",
   "metadata": {},
   "source": [
    "Create run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We look at the first 10 results of the run:\\n')\n",
    "run.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = retrieval_pipeline(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78819bca",
   "metadata": {},
   "source": [
    "Retrival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37da475",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_and_normalize_run(run, output_file=output_directory, system_name='BM25', depth=1000)\n",
    "\n",
    "print(\"Persist Run and normalize run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70db8c9",
   "metadata": {},
   "source": [
    "Persist Run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
